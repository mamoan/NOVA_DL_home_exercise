{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mamoan/NOVA_DL_home_exercise/blob/main/6_Post_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO_zYDMid4vq"
      },
      "source": [
        "# 6 - Post-processing\n",
        "## Clean-up (removing duplicates and edge detections) üìù-->üßπüìù\n",
        "## Converting YOLO predictions from image to map space  üßπüìù--> üó∫Ô∏è\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEk24axiMqTm"
      },
      "outputs": [],
      "source": [
        "path_to_predicted_list = [\"/content/drive/MyDrive/NOVA_course_home_exercise/data/tiles/10m_galbyveien_20230504_sun\", \"/content/drive/MyDrive/NOVA_course_home_exercise/data/tiles/10m_braatan_40m_20230605_sun\", \"/content/drive/MyDrive/NOVA_course_home_exercise/data/tiles/10m_krakstad_202304_sun\", \"/content/drive/MyDrive/NOVA_course_home_exercise/data/tiles/10m_ortho_hobol_042222_mavic_sun\", \"/content/drive/MyDrive/NOVA_course_home_exercise/data/annotated_data/test/images/predict_tiles_ML\", \"/content/drive/MyDrive/NOVA_course_home_exercise/data/annotated_data/test/images/predict_tiles_ML_small\"]\n",
        "path_to_predicted_list1 = [\"/content/drive/MyDrive/NOVA_course_home_exercise/data/tiles/10m_galbyveien_20230504_sun\", \"/content/drive/MyDrive/NOVA_course_home_exercise/data/tiles/10m_braatan_40m_20230605_sun\", \"/content/drive/MyDrive/NOVA_course_home_exercise/data/tiles/10m_krakstad_202304_sun\", \"/content/drive/MyDrive/NOVA_course_home_exercise/data/tiles/10m_ortho_hobol_042222_mavic_sun\"]\n",
        "buffer_size_m=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMO1huGlOpQb"
      },
      "outputs": [],
      "source": [
        "path_to_tile_index_list = [path_to_predicted_list1[0]+\"/galbyveien_20230504_sun_tile_index.shp\", path_to_predicted_list1[1]+\"/braatan_40m_20230605_sun_tile_index.shp\", path_to_predicted_list1[2]+\"/krakstad_202304_sun_tile_index.shp\", path_to_predicted_list1[3]+\"/ortho_hobol_042222_mavic_sun_tile_index.shp\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFPdaljuQOLE"
      },
      "outputs": [],
      "source": [
        "path_to_tile_index_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpYYou9qiMwT"
      },
      "source": [
        "## 6.1 load required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqqYchHzeoRG"
      },
      "outputs": [],
      "source": [
        "!pip install geopandas\n",
        "# general libraries\n",
        "import os, glob\n",
        "from pathlib import Path\n",
        "\n",
        "# Geospatial libraries\n",
        "import geopandas as gpd\n",
        "from osgeo import gdal, osr\n",
        "from shapely.geometry import Polygon\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn44NN6Kfvfh",
        "outputId": "52fb8292-c6d8-41ed-b1d4-a47c64418268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YQBEl-ZfAz3"
      },
      "source": [
        "## 6.2 Get necessary files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayv9kmKYQ9dI"
      },
      "outputs": [],
      "source": [
        "gtiffs = [None] * 4\n",
        "labels = [None] * 4\n",
        "labels_small = [None] * 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejV09c2uSxAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4c8f966-1372-4526-c044-7cbc7a32e31f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/NOVA_course_home_exercise/data/tiles/10m_galbyveien_20230504_sun',\n",
              " '/content/drive/MyDrive/NOVA_course_home_exercise/data/tiles/10m_braatan_40m_20230605_sun',\n",
              " '/content/drive/MyDrive/NOVA_course_home_exercise/data/tiles/10m_krakstad_202304_sun',\n",
              " '/content/drive/MyDrive/NOVA_course_home_exercise/data/tiles/10m_ortho_hobol_042222_mavic_sun']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "path_to_predicted_list1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlAPIs1EaAhG"
      },
      "outputs": [],
      "source": [
        "path_to_orthomosaics = [\"/content/drive/MyDrive/NOVA_course_home_exercise/data/orthomosaics/test_data/galbyveien_20230504_sun.tif\", \"/content/drive/MyDrive/NOVA_course_home_exercise/data/orthomosaics/test_data/braatan_40m_20230605_sun.tif\", \"/content/drive/MyDrive/NOVA_course_home_exercise/data/orthomosaics/test_data/10m_krakstad_202304_sun.tif\", \"/content/drive/MyDrive/NOVA_course_home_exercise/data/orthomosaics/test_data/10m_ortho_hobol_042222_mavic_sun.tif\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dv33qU_RcIP",
        "outputId": "adecbea5-c974-4d78-a4e3-e39b5968efe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There a total of 580 tif files\n",
            "There a total of 578 label files for the full model\n",
            "There a total of 579 label files for the small model\n",
            "There a total of 416 tif files\n",
            "There a total of 369 label files for the full model\n",
            "There a total of 363 label files for the small model\n",
            "There a total of 217 tif files\n",
            "There a total of 208 label files for the full model\n",
            "There a total of 212 label files for the small model\n",
            "There a total of 189 tif files\n",
            "There a total of 188 label files for the full model\n",
            "There a total of 187 label files for the small model\n"
          ]
        }
      ],
      "source": [
        "for i in range(4):\n",
        "  gtiffs[i] = glob.glob(path_to_predicted_list1[i] + \"/*.tif\") # all tif files\n",
        "  # gtiffs[i] = path_to_orthomosaics[i]\n",
        "  labels[i] = glob.glob(path_to_predicted_list1[i] + \"/predict_tiles/labels/*.txt\") # all label files\n",
        "  labels_small[i] = glob.glob(path_to_predicted_list1[i] + \"/predict_tiles_small/labels/*.txt\") # all label files\n",
        "  print(\"There a total of \"+str(len(gtiffs[i]))+\" tif files\")\n",
        "  print(\"There a total of \"+str(len(labels[i]))+\" label files for the full model\")\n",
        "  print(\"There a total of \"+str(len(labels_small[i]))+\" label files for the small model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFrQquOmYXxf"
      },
      "outputs": [],
      "source": [
        "# load tile index\n",
        "tile_index_list = [None] * 4\n",
        "tile_index_list = [gpd.read_file(path_to_tile_index_list[i]) for i in range(4)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5QDA64TYz97"
      },
      "outputs": [],
      "source": [
        "src_ds = [None] * 4\n",
        "src_ds = [gdal.Open(gtiffs[i][0]) for i in range(4)] # get raster datasource. Only the first tile is read but that is okay, because we are interested in the dimensions of the tiles and they should be the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzQvg-E_aTM-"
      },
      "outputs": [],
      "source": [
        "tile_size_m = [None] * 4\n",
        "tile_size_px = [None] * 4\n",
        "proj = [None] * 4\n",
        "EPSG_code = [None] * 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uAGYjEnZOZ6",
        "outputId": "91d8048b-37f9-40e8-b808-ca6ffafd6ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resolution: 0.01 m\n",
            "EPSG: 25832\n",
            "Resolution: 0.01 m\n",
            "EPSG: 25832\n",
            "Resolution: 0.01 m\n",
            "EPSG: 25832\n",
            "Resolution: 0.01 m\n",
            "EPSG: 25832\n"
          ]
        }
      ],
      "source": [
        "for i in range(4):\n",
        "  _, xres, _, _, _, yres  = src_ds[i].GetGeoTransform() # get pixel size in meters\n",
        "  tile_size_m[i]=round(src_ds[i].RasterXSize*xres)\n",
        "  tile_size_px[i]= round(tile_size_m[i]/abs(xres)) # calculate the tile size in pixels. The tile size is different for the different drone mosaics.\n",
        "  proj[i] = osr.SpatialReference(wkt=src_ds[i].GetProjection())\n",
        "  EPSG_code[i]= proj[i].GetAttrValue('AUTHORITY',1)\n",
        "\n",
        "  print(\"Resolution: \"+str(round(xres,2))+\" m\")\n",
        "  print(\"EPSG: \"+str(EPSG_code[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6ixWi2if01c"
      },
      "source": [
        "## 6.2 Parse from YOLO (image space) to UTM coordinates (map space)\n",
        "\n",
        "To do this we have to make a nested loop that iterates through each predicted label .txt file and through each row (i.e. predicted bounding box) in the .txt file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN6vtIU1k5qV"
      },
      "source": [
        "But first we have to write a function to parse yolo coordinates (x,y,w,h) to x1, y1, x2, y2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlPXDO3rlJq2"
      },
      "outputs": [],
      "source": [
        "##########################################################################################################################################################################\n",
        "# YOLO to x1, y1, x2, y2 parsers: converts (x, y, width, height) YOLO format to (x1, y1, x2, y2)  format.\n",
        "# arguments:\n",
        "# - label_file: file with YOLO predictions(s) inside including: class, x, y, width, height, probabilities\n",
        "# - img_width - width of input image in pixels\n",
        "# - img_height - height of input image in pixels\n",
        "#Returns:\n",
        "# - a file with a row per predicted bounding box and the following columns: class, x1, y1, x2, y2, probability (note that the coordinates are still in image coordinates and NOT GEOGRAPHICAL ONES)\n",
        "\n",
        "##########################################################################################################################################################################\n",
        "\n",
        "def yolo2xy(label_file, img_width, img_height):\n",
        "    \"\"\"\n",
        "    Definition:\n",
        "Parameters:\n",
        "\"\"\"\n",
        "    lfile = open(label_file)\n",
        "    coords = []\n",
        "    all_coords = []\n",
        "    for line in lfile:\n",
        "        l = line.split(\" \")\n",
        "        label=list(map(float, list(map(float, l[0]))))\n",
        "        probabs=(l[5])\n",
        "        #print(probabs)\n",
        "        coords = list(map(float, list(map(float, l[1:6]))))\n",
        "        x1 = float(img_width) * (2.0 * float(coords[0]) - float(coords[2])) / 2.0\n",
        "        y1 = float(img_height) * (2.0 * float(coords[1]) - float(coords[3])) / 2.0\n",
        "        x2 = float(img_width) * (2.0 * float(coords[0]) + float(coords[2])) / 2.0\n",
        "        y2 = float(img_height) * (2.0 * float(coords[1]) + float(coords[3])) / 2.0\n",
        "        tmp = [int(label[0]), int(x1), int(y1), int(x2), int(y2), float(coords[4])]\n",
        "        all_coords.append(list(tmp))\n",
        "    lfile.close()\n",
        "    return all_coords\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels[2]"
      ],
      "metadata": {
        "id": "uF5grmLCiHRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lq5ZOjClQWn"
      },
      "source": [
        "Now we are ready to run the code bellow, which includes the above function. Labels are the labels for the full model, so I must remember to also run with labels from the small model later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5vupdwijoY6"
      },
      "outputs": [],
      "source": [
        "all_bboxes = None\n",
        "iter_all=0 # setup counter\n",
        "j = 0 # This is changed according to which area I want to do the parsing for\n",
        "labels = labels_small # Changed according to if I want to use prediction from the full or small model\n",
        "for lab in range(len(labels[j])):\n",
        "    print(str(round(lab/len(labels[j])*100))+\" % done!\", end=\"\\r\")\n",
        "    # Define one label file and select the corresponding geotiff image\n",
        "    label_file=labels[j][lab]\n",
        "    label_file_name=Path(label_file).stem # ortho name\n",
        "    for p in gtiffs[j]:\n",
        "        if Path(p).stem ==label_file_name:\n",
        "            gtiff_file=p\n",
        "\n",
        "    # determing image width and height\n",
        "    # try:\n",
        "    r = gdal.Open(gtiff_file)\n",
        "    # except:\n",
        "    #   print(\"no file\")\n",
        "    #   continue\n",
        "\n",
        "    img_width=r.RasterXSize\n",
        "    img_height=r.RasterYSize\n",
        "\n",
        "    # Convert from yolo coordinates to x1, y1, x2, y2,\n",
        "    coords = yolo2xy(label_file, img_width, img_height) # class, x1, y1, x2, y2, probability\n",
        "\n",
        "    # Convert from image to geographical coordinates\n",
        "    ## select tile polygon (from tile index shapefile) that corresponds to the label_file_name\n",
        "    # the other files are required by the gpd readfile\n",
        "\n",
        "\n",
        "    # tile_index is <class 'geopandas.geodataframe.GeoDataFrame'>\n",
        "    one_tile=tile_index_list[j][tile_index_list[j]['ID']==label_file_name+\".tif\"] # Select tile in tile_index that has ID equal to label_file_name\n",
        "\n",
        "    ## get tile bounding box geographical coordinates (UTM)\n",
        "    one_tile_XminUTM=one_tile.total_bounds[0]\n",
        "    one_tile_YminUTM=one_tile.total_bounds[1]\n",
        "    one_tile_XmaxUTM=one_tile.total_bounds[2]\n",
        "    one_tile_YmaxUTM=one_tile.total_bounds[3]\n",
        "\n",
        "    ## take inner buffer equal to the buffer_size_m\n",
        "    one_tile_innerB= one_tile\n",
        "    one_tile_innerB['geometry'] = one_tile_innerB.geometry.buffer(-(buffer_size_m/2))\n",
        "\n",
        "    ## get inner tile bounding boxes\n",
        "    one_tile_inner_XminUTM=one_tile_innerB.total_bounds[0]\n",
        "    one_tile_inner_YminUTM=one_tile_innerB.total_bounds[1]\n",
        "    one_tile_inner_XmaxUTM=one_tile_innerB.total_bounds[2]\n",
        "    one_tile_inner_YmaxUTM=one_tile_innerB.total_bounds[3]\n",
        "\n",
        "    # Now iterate through each bounding box and assign UTM coordinates and create a shapefile\n",
        "    bboxes_tile = None\n",
        "    for i in coords:\n",
        "        # print(\"inside coords\")\n",
        "        # Convert bounding box coordinates from image to geographical coords\n",
        "        X1_UTM=(i[1]*xres)+one_tile_XminUTM\n",
        "        Y1_UTM=(i[2]*yres)+one_tile_YminUTM+tile_size_m[j]\n",
        "        X2_UTM=(i[3]*xres)+one_tile_XminUTM\n",
        "        Y2_UTM=(i[4]*yres)+one_tile_YminUTM+tile_size_m[j]\n",
        "\n",
        "        # skip bounding box if its centroid is NOT within the inner tile (removing the overlap)\n",
        "        X_UTM= (X1_UTM+X2_UTM)/2\n",
        "        Y_UTM= (Y1_UTM+Y2_UTM)/2\n",
        "        if X_UTM<one_tile_inner_XminUTM or X_UTM>one_tile_inner_XmaxUTM or Y_UTM<one_tile_inner_YminUTM or Y_UTM>one_tile_inner_YmaxUTM:\n",
        "            #print(\"continue break\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        # Create polygon shape from geographical coords\n",
        "        lat_point_list = [Y1_UTM, Y1_UTM, Y2_UTM, Y2_UTM, Y1_UTM]\n",
        "        lon_point_list = [X1_UTM, X2_UTM, X2_UTM, X1_UTM, X1_UTM]\n",
        "        # try:\n",
        "        polygon_geom = Polygon(zip(lon_point_list, lat_point_list))\n",
        "        # except:\n",
        "        #   print(\"not sure what is going on\")\n",
        "        #   continue\n",
        "\n",
        "        crs = {'init': 'epsg:'+EPSG_code[j]}\n",
        "        data= {'class': [i[0]], 'prob': [i[5]]}\n",
        "        bbox = gpd.GeoDataFrame(data, crs=crs, geometry=[polygon_geom])\n",
        "\n",
        "        if (bboxes_tile is None):\n",
        "            bboxes_tile = bbox\n",
        "        else:\n",
        "            bboxes_tile = bboxes_tile.append(bbox)\n",
        "\n",
        "    # cleanup boxes (removing overlapping ones)\n",
        "    if bboxes_tile is not None:\n",
        "        # clean_boxes = bboxes_tile #cleanUp_boudingBoxes(bboxes_tile, iou_thresh)\n",
        "        if (all_bboxes is None):\n",
        "            all_bboxes = bboxes_tile\n",
        "        else :\n",
        "            all_bboxes = all_bboxes.append(bboxes_tile)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86G-T2e_8OKz",
        "outputId": "1d0b069c-74e8-4dd9-a0c7-e52717c9f7bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10m_galbyveien_20230504_sun\n"
          ]
        }
      ],
      "source": [
        "ortho_name= os.path.basename(path_to_predicted_list1[j]) # Check that the code was run for the intended area\n",
        "print(ortho_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74kSdUDHme-b"
      },
      "source": [
        "## 6.3 Export predictions shapefile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KSdcuzSko1T"
      },
      "outputs": [],
      "source": [
        "ortho_name= os.path.basename(path_to_predicted_list1[j])\n",
        "all_bboxes.to_file(path_to_predicted_list1[j] + \"/\" + ortho_name + \"_predictions_small_AM.shp\", driver='ESRI Shapefile') # turn this off if it's not needed"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There seemed to be some problems with these shapefiles when they were examined in QGiS. The bounding boxes did not encompass the trees as often as one would expect based on the test results in 7_model_evaluation."
      ],
      "metadata": {
        "id": "dK4ncZc_34le"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp2yX-bwrCWi"
      },
      "source": [
        "# Still, I try to use this map to validate how good the models are in terms of forestry domain-specific variables."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}