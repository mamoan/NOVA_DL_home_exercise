{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mamoan/NOVA_DL_home_exercise/blob/main/3_train_val_split.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 split the data into training (70%) and validation (30%)\n",
        "## OBJECTIVE: randomly split the annotated data into\n",
        "- *training* (70% of the tiles): set of data used for learning (by the model), that is, to fit the parameters to the machine learning model.\n",
        "- *validation* set (30%): Set of data used to provide an unbiased evaluation of a model fitted on the training dataset while tuning model hyperparameters.\n",
        "\n",
        "We also need a third test dataset for a fully independent evaluation of model's performance on unseen data. In this home exercise the test data are already taken out of the data.\n",
        "\n",
        "**OUTPUT:**\n",
        "- train and validation data organized in the following folders:\n",
        "\n",
        "```\n",
        "├── train\n",
        "│   ├── images\n",
        "│   └── labels\n",
        "├── val\n",
        "│   ├── images\n",
        "│   └── labels\n",
        "```\n"
      ],
      "metadata": {
        "id": "vcYhX5JPvnUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annotator_ID=8 # change this to your folder ID\n",
        "path_to_tiles_small=\"/content/drive/MyDrive/NOVA_course_home_exercise/data/annotated_data/train/\"+str(annotator_ID)\n",
        "path_to_tiles_full=\"/content/drive/MyDrive/NOVA_course_home_exercise/data/annotated_data/train/full_data\"\n",
        "\n",
        "# define split for training and validation\n",
        "split_train= 0.7 #\n",
        "split_val=1-split_train"
      ],
      "metadata": {
        "id": "ESxfoDbRtkVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Load libraries"
      ],
      "metadata": {
        "id": "IOOTsKg9tf-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# mount google drive\n",
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KQ9Ofi8kt8AI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b151ddff-d04f-4d0d-a806-355e28918b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Create train and validation directories and subdivide each into \"images\" and \"labels\" sub-directories"
      ],
      "metadata": {
        "id": "6hLdXNOguHeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Full data\n",
        "train_dir_full = os.path.join(path_to_tiles_full, \"train\")\n",
        "os.makedirs(train_dir_full, exist_ok=True) # creates new directory for training data\n",
        "val_dir_full = os.path.join(path_to_tiles_full, \"val\")\n",
        "os.makedirs(val_dir_full, exist_ok=True) # creates new directory for validation data\n",
        "val_img_dir_full = os.path.join(path_to_tiles_full, \"val\",\"images\")\n",
        "os.makedirs(val_img_dir_full, exist_ok=True) # creates new directory for training data\n",
        "train_img_dir_full = os.path.join(path_to_tiles_full, \"train\",\"images\")\n",
        "os.makedirs(train_img_dir_full, exist_ok=True) # creates new directory for training data\n",
        "val_ann_dir_full = os.path.join(path_to_tiles_full, \"val\",\"labels\")\n",
        "os.makedirs(val_ann_dir_full, exist_ok=True) # creates new directory for training data\n",
        "train_ann_dir_full = os.path.join(path_to_tiles_full, \"train\",\"labels\")\n",
        "os.makedirs(train_ann_dir_full, exist_ok=True) # creates new directory for training data"
      ],
      "metadata": {
        "id": "tvlFsdcvgMeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Smaller dataset\n",
        "train_dir_small = os.path.join(path_to_tiles_small, \"train\")\n",
        "os.makedirs(train_dir_small, exist_ok=True) # creates new directory for training data\n",
        "val_dir_small = os.path.join(path_to_tiles_small, \"val\")\n",
        "os.makedirs(val_dir_small, exist_ok=True) # creates new directory for validation data\n",
        "val_img_dir_small = os.path.join(path_to_tiles_small, \"val\",\"images\")\n",
        "os.makedirs(val_img_dir_small, exist_ok=True) # creates new directory for training data\n",
        "train_img_dir_small = os.path.join(path_to_tiles_small, \"train\",\"images\")\n",
        "os.makedirs(train_img_dir_small, exist_ok=True) # creates new directory for training data\n",
        "val_ann_dir_small = os.path.join(path_to_tiles_small, \"val\",\"labels\")\n",
        "os.makedirs(val_ann_dir_small, exist_ok=True) # creates new directory for training data\n",
        "train_ann_dir_small = os.path.join(path_to_tiles_small, \"train\",\"labels\")\n",
        "os.makedirs(train_ann_dir_small, exist_ok=True) # creates new directory for training data"
      ],
      "metadata": {
        "id": "tQ_MGFOTgfe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Randomly sample tiles"
      ],
      "metadata": {
        "id": "RpooLhCauWx_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For smaller dataset"
      ],
      "metadata": {
        "id": "wNgQ7lRihcuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all the .txt files in the data directory\n",
        "txt_files = [f for f in os.listdir(path_to_tiles_small) if f.endswith(\".txt\")]\n",
        "img_files = [f for f in os.listdir(path_to_tiles_small) if f.endswith(\".tif\")]"
      ],
      "metadata": {
        "id": "sAH2eQwTF-fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove .txt files that have no image (not sure why ?)\n",
        "txt_files_with_tif = []\n",
        "for txt_file in txt_files:\n",
        "    # get the base name of the text file\n",
        "    txt_base_name = os.path.basename(txt_file)\n",
        "    # replace the file extension with .tif to get the corresponding tif file name\n",
        "    img_file = os.path.join(os.path.dirname(txt_file), os.path.splitext(txt_base_name)[0] + '.tif')\n",
        "    img_file=path_to_tiles_small+\"/\"+img_file\n",
        "    #print(\"txt: \"+txt_file)\n",
        "    #print(\"tif: \"+img_file)\n",
        "    # check if the tif file exists\n",
        "    if os.path.exists(img_file):\n",
        "      #print(\"path to image \" + img_file + \" does not exist!\")\n",
        "      txt_files_with_tif.append(txt_file)\n",
        "\n"
      ],
      "metadata": {
        "id": "l6_I5DQEDd0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_files=txt_files_with_tif\n",
        "\n",
        "# Shuffle the list of text files\n",
        "random.shuffle(txt_files)\n",
        "#train=random.sample(txt_files, )\n",
        "\n",
        "# Calculate the number of files for the train and validation sets\n",
        "train_size = int(0.7 * len(txt_files))\n",
        "val_size = len(txt_files) - train_size"
      ],
      "metadata": {
        "id": "2Olsju2esPOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(txt_files))\n",
        "print(val_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRHwz1Asckkz",
        "outputId": "14ba2a8c-4cbe-4c76-decf-bd760ed085d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Move the text annotation files and respective images to the train and validation directories"
      ],
      "metadata": {
        "id": "DwIl8JDcyBey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate through each annotated .txt file\n",
        "for i, txt_file in enumerate(txt_files):\n",
        "    if i < train_size:\n",
        "        dest_dir = train_dir_small\n",
        "    else:\n",
        "        dest_dir = val_dir_small\n",
        "    #print(\"path to \"+path_to_tiles+\"/\"+txt_file+\" exists: \"+ str(os.path.exists(txt_file)))\n",
        "    if os.path.exists(path_to_tiles_small+\"/\"+txt_file):\n",
        "      src_file = os.path.join(path_to_tiles_small, txt_file)\n",
        "      src_img = os.path.join(path_to_tiles_small, os.path.splitext(txt_file)[0]+\".tif\")\n",
        "      if os.path.exists(src_img):\n",
        "        dest_file = os.path.join(dest_dir,\"labels\", txt_file)\n",
        "        dest_img = os.path.join(dest_dir,\"images\", os.path.splitext(txt_file)[0]+\".tif\")\n",
        "        #print(\"copying files\")\n",
        "        shutil.move(src_file, dest_file)\n",
        "        shutil.move(src_img, dest_img)"
      ],
      "metadata": {
        "id": "6sGgm68syA51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### For the full dataset"
      ],
      "metadata": {
        "id": "Cs1UJMrhyZA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all the .txt files in the data directory\n",
        "txt_files = [f for f in os.listdir(path_to_tiles_full) if f.endswith(\".txt\")]\n",
        "img_files = [f for f in os.listdir(path_to_tiles_full) if f.endswith(\".tif\")]"
      ],
      "metadata": {
        "id": "nRmqAAZGbnxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(txt_files))\n",
        "print(len(img_files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeP90yqccB4V",
        "outputId": "23cc8b75-f32b-4039-f2c0-d47e51b72d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383\n",
            "3039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove .txt files that have no image (not sure why ?)\n",
        "txt_files_with_tif = []\n",
        "for txt_file in txt_files:\n",
        "    # get the base name of the text file\n",
        "    txt_base_name = os.path.basename(txt_file)\n",
        "    # replace the file extension with .tif to get the corresponding tif file name\n",
        "    img_file = os.path.join(os.path.dirname(txt_file), os.path.splitext(txt_base_name)[0] + '.tif')\n",
        "    img_file=path_to_tiles_full+\"/\"+img_file\n",
        "    #print(\"txt: \"+txt_file)\n",
        "    #print(\"tif: \"+img_file)\n",
        "    # check if the tif file exists\n",
        "    if os.path.exists(img_file):\n",
        "      #print(\"path to image \" + img_file + \" does not exist!\")\n",
        "      txt_files_with_tif.append(txt_file)"
      ],
      "metadata": {
        "id": "w9jhWGLmbxnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_files=txt_files_with_tif\n",
        "\n",
        "# Shuffle the list of text files\n",
        "random.shuffle(txt_files)\n",
        "#train=random.sample(txt_files, )\n",
        "\n",
        "# Calculate the number of files for the train and validation sets\n",
        "train_size = int(0.7 * len(txt_files))\n",
        "val_size = len(txt_files) - train_size"
      ],
      "metadata": {
        "id": "zrSryR-rb5VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate through each annotated .txt file\n",
        "for i, txt_file in enumerate(txt_files):\n",
        "    if i < train_size:\n",
        "        dest_dir = train_dir\n",
        "    else:\n",
        "        dest_dir = val_dir\n",
        "    print(\"path to \"+path_to_tiles_full+\"/\"+txt_file+\" exists: \"+ str(os.path.exists(txt_file)))\n",
        "    if os.path.exists(path_to_tiles_full+\"/\"+txt_file):\n",
        "      src_file = os.path.join(path_to_tiles_full, txt_file)\n",
        "      src_img = os.path.join(path_to_tiles_full, os.path.splitext(txt_file)[0]+\".tif\")\n",
        "      if os.path.exists(src_img):\n",
        "        dest_file = os.path.join(dest_dir,\"labels\", txt_file)\n",
        "        dest_img = os.path.join(dest_dir,\"images\", os.path.splitext(txt_file)[0]+\".tif\")\n",
        "        #print(\"copying files\")\n",
        "        shutil.move(src_file, dest_file)\n",
        "        shutil.move(src_img, dest_img)"
      ],
      "metadata": {
        "id": "S8W3pePIb8Se"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}